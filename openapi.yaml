openapi: 3.0.1
info:
  title: blocktool.js API
  description: API for language models
  version: 0.0.1
servers:
  - url: https://blocktool.com/api
paths:
  /v1/completion:
    post:
      summary: Generates completion for a given prompt
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                frequency_penalty:
                  type: number
                max_tokens:
                  type: integer
                  description: Maximum number of tokens to generate in the completion.
                  example: 20
                model:
                  type: string
                  description: ID of the model to use.
                  example: claude-v1.0
                presence_penalty:
                  type: number
                prompt:
                  type: object
                  description: The prompt to generate completions for.
                  properties:
                    messages:
                      type: array
                      items:
                        type: object
                        properties:
                          role:
                            type: string
                            examples: '"assistant", "system" or "user"'
                          content:
                            type: string
                      description: The messages to generate chat completions for, in the chat format.
                    data:
                      type: object
                      additionalProperties: true
                      description: JSON dictionary with dynamic data that can be used in messages templating
                  example: {"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "{{user_question}}"}], "data": {"user_question": "What is the capital of France?"}}
                session:
                  type: string
                  description: A unique identifier representing a user session. To help grouping completion requests
                stream:
                  type: boolean
                  description: Whether to incrementally stream the response using SSE.
                  example: false
                temperature:
                  type: number
                  description: Amount of randomness injected into the response. Ranges from 0 to 1.
                  example: 1
              required:
                - model
                - max_tokens
      responses:
        200:
          description: Successful completion
          content:
            application/json:
              schema:
                type: object
                properties:
                  id:
                    type: string
                  model:
                    type: string
                  text:
                    type: string
                    description: The resulting completion up to and excluding the stop sequences.
                  stop_reason:
                    type: string
                    enum: ["stop_sequence", "max_tokens"]
                    description: The reason we stopped sampling.
                  usage:
                    type: object
                    properties:
                      prompt:
                        type: number
                        description: Cost of the prompt in USD
                      completion:
                        type: number
                        description: Cost of the completion in USD
        400:
          description: Bad request
        500:
          description: Internal server error
